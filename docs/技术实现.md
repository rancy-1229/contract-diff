# 合同差异AI审查系统技术实现文档

## 概述

本文档详细描述了合同差异AI审查系统的技术实现，包括前后端架构、AI审查流程、数据库设计、API接口设计等核心内容。

## 系统架构

### 整体架构图
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   前端 (React)   │    │   后端 (FastAPI) │    │   AI服务 (豆包)  │
│                 │    │                 │    │                 │
│ - 文档上传      │◄──►│ - 文档对比      │◄──►│ - 合同审查      │
│ - 差异展示      │    │ - AI审查调度    │    │ - 风险评估      │
│ - AI审查结果    │    │ - 结果存储      │    │ - 合规检查      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                              │
                              ▼
                       ┌─────────────────┐
                       │  数据库 (PostgreSQL) │
                       │                 │
                       │ - 文档存储      │
                       │ - 对比结果      │
                       │ - AI审查记录    │
                       └─────────────────┘
```

## 核心功能模块

### 1. 文档解析与对比模块

#### 1.1 文档解析架构
- **技术栈**: PyMuPDF (fitz) + python-docx
- **支持格式**: PDF、Word文档
- **实现位置**: `backend/app/utils/file_parser.py`

**5步解析流程**:
```python
async def parse_document(self, file_path: str, file_type: str) -> Dict:
    """文档解析的5步流程"""
    # 步骤1: 格式转换 (docx -> pdf)
    if file_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
        pdf_path = await self._convert_docx_to_pdf(file_path)
    
    # 步骤2: 文本和坐标提取
    document_data = await self._extract_text_and_coordinates(pdf_path)
    
    # 步骤3: 构建字符序列映射
    char_sequence_map = mapper.build_char_sequence_map(document_data)
    document_data["char_sequence_map"] = char_sequence_map
    
    return document_data
```

#### 1.2 PDF文本与坐标提取
- **核心库**: PyMuPDF (fitz)
- **提取内容**: 文本内容、字符坐标、字体信息、页面结构
- **精度**: 字符级别的精确坐标定位

```python
async def _extract_text_and_coordinates(self, pdf_path: str) -> Dict:
    """使用PyMuPDF提取文本和坐标信息"""
    doc = fitz.open(pdf_path)
    pages_data = []
    full_text = ""
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        text_dict = page.get_text("dict")  # 获取结构化文本信息
        
        page_data = {
            "page_index": page_num,
            "width": page.rect.width,
            "height": page.rect.height,
            "blocks": [],
            "char_sequence": []  # 字符序列，用于坐标映射
        }
        
        char_index = 0
        for block in text_dict["blocks"]:
            for line in block["lines"]:
                for span in line["spans"]:
                    # 为每个字符创建精确的坐标信息
                    char_bboxes = self._calculate_char_bboxes_precise(
                        span["text"], span["bbox"], span["size"]
                    )
                    
                    # 构建字符序列映射
                    for i, char in enumerate(span["text"]):
                        page_data["char_sequence"].append({
                            "char": char,
                            "char_index": char_index + i,
                            "bbox": char_bboxes[i],
                            "font": span["font"],
                            "size": span["size"]
                        })
                    
                    char_index += len(span["text"])
                    full_text += span["text"]
    
    return {"pages": pages_data, "full_text": full_text}
```

#### 1.3 字符级坐标计算
- **算法**: 基于字体大小和文本宽度的精确计算
- **特点**: 支持不同字体、大小的字符坐标定位

```python
def _calculate_char_bboxes_precise(self, text: str, span_bbox: List[float], font_size: float) -> List[List[float]]:
    """计算每个字符的精确边界框"""
    x0, y0, x1, y1 = span_bbox
    char_bboxes = []
    
    # 使用更精确的字符宽度计算
    total_width = x1 - x0
    char_width = total_width / len(text) if len(text) > 0 else 0
    
    for i, char in enumerate(text):
        char_x0 = x0 + i * char_width
        char_x1 = x0 + (i + 1) * char_width
        
        char_bbox = [
            max(0, char_x0),
            max(0, y0),
            min(x1, char_x1),
            min(y1, y0 + font_size)
        ]
        char_bboxes.append(char_bbox)
    
    return char_bboxes
```

#### 1.4 差异检测算法
- **核心算法**: Python difflib.SequenceMatcher
- **检测类型**: ADD（新增）、DELETE（删除）、MODIFY（修改）
- **实现位置**: `backend/app/utils/diff_engine.py`

```python
async def compare_documents(self, standard_data: Dict, target_data: Dict) -> Dict:
    """对比两个文档并返回差异信息"""
    # 步骤4: 差异对比
    standard_text = standard_data.get("full_text", "")
    target_text = target_data.get("full_text", "")
    
    # 使用difflib进行文本对比
    diff_list = await self._compare_texts(standard_text, target_text, standard_data, target_data)
    
    # 步骤5: 坐标映射
    mapped_diff_list = mapper.map_diff_to_coordinates(diff_list, {
        "standard": standard_map,
        "target": target_map
    })
    
    return {"diff_list": mapped_diff_list, "summary": self.generate_summary(mapped_diff_list)}
```

#### 1.5 差异类型判断算法
- **算法逻辑**: 基于SequenceMatcher的opcodes分析
- **智能分类**: 自动判断差异类型（增删改）

```python
async def _compare_texts(self, text1: str, text2: str, standard_data: Dict, target_data: Dict) -> List[Dict]:
    """使用算法进行差异类型判断"""
    matcher = difflib.SequenceMatcher(None, text1, text2)
    diff_list = []
    
    # 收集所有差异操作
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'delete':
            # 删除操作
            deleted_text = text1[i1:i2]
            diff_item = await self._create_diff_item_by_type(
                f"diff_{diff_count}", "DELETE", deleted_text, None, i1, i2, None, None, 0
            )
        elif tag == 'insert':
            # 新增操作
            inserted_text = text2[j1:j2]
            diff_item = await self._create_diff_item_by_type(
                f"diff_{diff_count}", "ADD", None, inserted_text, None, None, j1, j2, 0
            )
        elif tag == 'replace':
            # 修改操作
            deleted_text = text1[i1:i2]
            inserted_text = text2[j1:j2]
            diff_item = await self._create_diff_item_by_type(
                f"diff_{diff_count}", "MODIFY", deleted_text, inserted_text, i1, i2, j1, j2, 0
            )
    
    return diff_list
```

#### 1.6 坐标映射系统
- **核心功能**: 将字符级差异映射回PDF坐标
- **实现位置**: `backend/app/utils/coordinate_mapper.py`
- **坐标转换**: PDF坐标 → 图片坐标

```python
def map_diff_to_coordinates(self, diff_list: List[Dict], char_sequence_maps: Dict[str, Dict]) -> List[Dict]:
    """将差异结果映射回坐标"""
    mapped_diffs = []
    
    for diff_item in diff_list:
        mapped_diff = {
            "element_id": diff_item["element_id"],
            "type": diff_item["type"],
            "status": diff_item["status"],
            "page_index": diff_item["page_index"],
            "diff": []
        }
        
        # 映射每个差异组到坐标
        for diff_group in diff_item.get("diff", []):
            mapped_group = []
            for char_info in diff_group:
                # 查找字符在映射中的位置
                char_key = self._find_char_key(char_info, char_sequence_maps)
                
                if char_key:
                    mapped_char = char_sequence_maps[char_key].copy()
                    # 转换PDF坐标到图片坐标
                    pdf_bbox = mapped_char.get("bbox", [0, 0, 0, 0])
                    image_bbox = self._convert_pdf_coords_to_image_coords(pdf_bbox)
                    mapped_char.update({"char_polygons": [image_bbox]})
                    mapped_group.append(mapped_char)
            
            mapped_diff["diff"].append(mapped_group)
    
    return mapped_diffs
```

### 2. AI审查模块

#### 2.1 AI服务集成
- **AI模型**: 豆包 (Doubao) - `doubao-seed-1-6-flash-250828`
- **API接口**: Volces Ark API
- **实现位置**: `backend/app/services/ai_review_service.py`
- **超时设置**: 300秒，支持重试机制

```python
class AIReviewService:
    def __init__(self):
        self.base_url = settings.ARK_BASE_URL
        self.api_key = settings.ARK_API_KEY
        self.model = settings.ARK_MODEL
        self.client = httpx.AsyncClient(timeout=300.0)
```

#### 2.2 段落级上下文提取
- **核心功能**: 将字符级差异扩展为段落级上下文
- **技术实现**: 基于`sub_text_index`定位原文段落
- **上下文大小**: 默认200字符，可配置

```python
def extract_paragraph_context(self, diff_data: Dict, standard_doc_content: Dict = None, target_doc_content: Dict = None) -> Dict:
    """提取差异的段落级上下文"""
    try:
        # 1. 从diff字段中提取文本和位置信息
        diff = diff_data.get('diff', [])
        if diff and len(diff) >= 2:
            old_text = ''
            new_text = ''
            old_start_index = None
            new_start_index = None
            
            # 提取原文本和位置
            if diff[0] and len(diff[0]) > 0:
                old_item = diff[0][0]
                old_text = old_item.get('text', '')
                if 'sub_info' in old_item and old_item['sub_info']:
                    old_start_index = old_item['sub_info'][0].get('sub_text_index', {}).get('start_index')
            
            # 提取新文本和位置
            if diff[1] and len(diff[1]) > 0:
                new_item = diff[1][0]
                new_text = new_item.get('text', '')
                if 'sub_info' in new_item and new_item['sub_info']:
                    new_start_index = new_item['sub_info'][0].get('sub_text_index', {}).get('start_index')
            
            # 2. 从文档内容中提取段落级上下文
            if old_start_index is not None and standard_doc_content:
                old_context = self._extract_context_around_position(standard_doc_content, old_start_index)
            else:
                old_context = old_text
            
            if new_start_index is not None and target_doc_content:
                new_context = self._extract_context_around_position(target_doc_content, new_start_index)
            else:
                new_context = new_text
            
            return {
                'standard_text': old_context,
                'target_text': new_context,
                'char_diff': f"'{old_text}' -> '{new_text}'"
            }
    except Exception as e:
        logger.error(f"提取段落上下文失败: {str(e)}")
        return {'standard_text': '', 'target_text': '', 'char_diff': ''}
```

#### 2.3 上下文位置提取算法
- **算法**: 基于字符位置的前后文提取
- **边界处理**: 智能识别句子和段落边界

```python
def _extract_context_around_position(self, doc_content: Dict, position: int, context_size: int = 200) -> str:
    """提取指定位置周围的上下文"""
    try:
        full_text = doc_content.get('full_text', '')
        if not full_text or position < 0 or position >= len(full_text):
            return ''
        
        # 计算提取范围
        start_pos = max(0, position - context_size // 2)
        end_pos = min(len(full_text), position + context_size // 2)
        
        # 尝试在句子边界处截断
        context_text = full_text[start_pos:end_pos]
        
        # 向前查找句子开始
        sentence_start = context_text.find('。')
        if sentence_start > 0:
            context_text = context_text[sentence_start + 1:]
        
        # 向后查找句子结束
        sentence_end = context_text.rfind('。')
        if sentence_end > 0:
            context_text = context_text[:sentence_end + 1]
        
        return context_text.strip()
    except Exception as e:
        logger.error(f"提取上下文失败: {str(e)}")
        return ''
```

#### 2.4 批量AI审查
- **优化策略**: 批量发送多个差异给AI模型
- **输出格式**: JSON格式，便于解析
- **错误处理**: 重试机制 + 默认结果

```python
async def review_multiple_diffs(self, diff_list: List[Dict], standard_doc_content: Dict = None, target_doc_content: Dict = None) -> List[Dict]:
    """批量审查多个差异 - 一次性发送给AI模型"""
    try:
        # 构建批量审查的提示词
        prompt_parts = [
            "你是合同审查专家，请分析以下合同条款差异并给出风险评估和修改建议。\n"
        ]
        
        for i, diff_data in enumerate(diff_list):
            context_info = self.extract_paragraph_context(diff_data, standard_doc_content, target_doc_content)
            diff_id = self.generate_diff_id(diff_data)
            
            prompt_parts.append(f"""
差异 {i+1}:
差异ID: {diff_id}
标准条款: {context_info['standard_text']}
目标条款: {context_info['target_text']}
字符级差异: {context_info.get('char_diff', '')}
""")
        
        prompt_parts.append("""
请为每个差异提供以下信息：
1. 风险级别（高/中/低）
2. 法律合规性（符合/不符合/部分符合）
3. 审查意见和修改建议

请以JSON格式返回结果，格式如下：
[
  {
    "diff_id": "差异ID",
    "risk_level": "风险级别",
    "compliance": "合规性",
    "review_suggestions": "审查意见",
    "raw_ai_response": "原始AI响应"
  }
]
""")
        
        # 调用AI模型
        ai_response = await self._call_ai_api("\n".join(prompt_parts))
        results = self.parse_batch_ai_response(ai_response, diff_list)
        return results
        
    except Exception as e:
        logger.error(f"批量AI审查失败: {str(e)}")
        return self._create_default_results(diff_list)
```

#### 2.5 AI API调用与重试机制
- **重试策略**: 指数退避，最多3次重试
- **超时处理**: 300秒超时
- **错误日志**: 详细的错误信息记录

```python
async def _call_ai_api(self, prompt: str) -> str:
    """调用AI API，支持重试机制"""
    headers = {
        "Authorization": f"Bearer {self.api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": self.model,
        "messages": [
            {"role": "system", "content": "你是合同审查专家，请分析以下合同条款差异并给出风险评估和修改建议。"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "max_tokens": 2000
    }

    max_retries = 3
    last_exception = None

    for attempt in range(max_retries):
        try:
            url = self.base_url.rstrip('/') + '/chat/completions'
            response = await self.client.post(url, headers=headers, json=data)
            response.raise_for_status()
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
            
        except Exception as e:
            last_exception = e
            if attempt == max_retries - 1:
                # 最后一次尝试失败，记录错误并抛出异常
                logger.error(f"AI API调用失败: {str(e)}")
                raise Exception(f"AI API调用失败: {str(e)}")
            else:
                # 等待一段时间后重试
                await asyncio.sleep(2 ** attempt)  # 指数退避
```

### 3. 异步任务处理

#### 3.1 后台任务调度
- **技术栈**: FastAPI BackgroundTasks
- **实现位置**: `backend/app/api/comparisons.py`

```python
@router.post("/", response_model=dict)
async def create_comparison(request: ComparisonRequest, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    # 1. 执行文档对比
    # 2. 保存对比结果
    # 3. 如果启用AI审查，启动后台任务
    if request.enable_ai_review and comparison_result["diff_list"]:
        background_tasks.add_task(_perform_batch_ai_review, db, str(comparison.id), comparison_result["diff_list"])
```

#### 3.2 轮询机制
- **前端实现**: React useEffect + setTimeout
- **轮询策略**: 每3秒轮询一次，最多100次（300秒）
- **实现位置**: `frontend/src/components/ComparisonDisplay.tsx`

```typescript
// 轮询获取AI审查结果
const pollAiReviews = async () => {
  let attempts = 0;
  const maxAttempts = 10;
  const pollInterval = 3000;
  
  const poll = async () => {
    // 轮询逻辑
    if (reviews.length > 0) {
      setAiReviews(reviews);
      setAiReviewStatus('completed');
      return;
    }
    // 继续轮询或超时处理
  };
};
```

## 数据库设计

### 核心表结构

#### 1. documents 表
```sql
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    original_filename VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_type VARCHAR(50) NOT NULL,
    content_json JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

#### 2. comparisons 表
```sql
CREATE TABLE comparisons (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    standard_document_id UUID REFERENCES documents(id),
    target_document_id UUID REFERENCES documents(id),
    result_json JSONB,
    status VARCHAR(20) DEFAULT 'pending',
    differences_count INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

#### 3. diff_reviews 表
```sql
CREATE TABLE diff_reviews (
    id SERIAL PRIMARY KEY,
    comparison_id UUID REFERENCES comparisons(id),
    diff_id VARCHAR(100) NOT NULL,
    risk_level VARCHAR(10) NOT NULL,
    compliance VARCHAR(20) NOT NULL,
    review_suggestions TEXT NOT NULL,
    raw_ai_response TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

## API接口设计

### 1. 文档对比接口

#### POST /api/comparisons/
```json
{
  "standard_document_id": "uuid",
  "target_document_id": "uuid", 
  "enable_ai_review": true
}
```

**响应**:
```json
{
  "comparison_id": "uuid",
  "standard_images": ["/images/..."],
  "target_images": ["/images/..."],
  "diff_list": [...],
  "summary": {
    "total_differences": 23,
    "additions": 4,
    "deletions": 4,
    "modifications": 15
  },
  "ai_review_enabled": true
}
```

### 2. AI审查接口

#### GET /api/ai-review/comparisons/{comparison_id}/review
**响应**:
```json
[
  {
    "id": 1,
    "comparison_id": "uuid",
    "diff_id": "diff_1",
    "risk_level": "高",
    "compliance": "不符合",
    "review_suggestions": "详细的风险评估和修改建议",
    "raw_ai_response": "原始AI响应",
    "created_at": "2025-09-24T16:48:49Z"
  }
]
```

## 前端技术实现

### 1. 组件架构

#### ComparisonDisplay 组件
- **职责**: 主要的对比结果展示组件
- **功能**: 图片展示、差异列表、AI审查状态管理

#### DiffSidebar 组件  
- **职责**: 差异列表和AI审查结果展示
- **功能**: 差异分类、AI审查状态显示、手动刷新

### 2. 状态管理

```typescript
interface ComparisonDisplayState {
  currentPage: number;
  aiReviews: DiffReview[];
  aiReviewLoading: boolean;
  aiReviewStatus: 'idle' | 'processing' | 'completed' | 'error';
}
```

### 3. 轮询机制实现

```typescript
useEffect(() => {
  if (aiReviewEnabled && comparisonId) {
    setAiReviewStatus('processing');
    
    const pollAiReviews = async () => {
      // 轮询逻辑
      const poll = async () => {
        const response = await fetch(`/api/ai-review/comparisons/${comparisonId}/review`);
        const reviews = await response.json();
        
        if (reviews.length > 0) {
          setAiReviews(reviews);
          setAiReviewStatus('completed');
          return;
        }
        
        // 继续轮询
        if (attempts < maxAttempts) {
          setTimeout(poll, pollInterval);
        }
      };
      
      setTimeout(poll, 3000);
    };
    
    pollAiReviews();
  }
}, [comparisonId, aiReviewEnabled]);
```

## 关键技术特性

### 1. 字符级差异检测
- **精度**: 精确到单个字符
- **支持操作**: 增加、删除、修改
- **坐标映射**: 支持PDF坐标到像素坐标的转换

### 2. 段落级AI审查
- **上下文提取**: 基于字符位置提取完整段落
- **智能分析**: AI模型分析段落级语义差异
- **风险评估**: 高/中/低三级风险分类

### 3. 异步处理架构
- **后台任务**: FastAPI BackgroundTasks
- **轮询机制**: 前端主动轮询结果
- **状态管理**: 实时状态反馈

### 4. 错误处理与重试
- **AI API重试**: 指数退避策略，最多3次重试
- **前端轮询**: 最多100次轮询，300秒超时
- **手动刷新**: 用户可手动重试

## 性能优化

### 1. 批量处理
- **AI审查**: 一次性处理所有差异，减少API调用次数
- **数据库**: 批量插入AI审查结果

### 2. 缓存策略
- **文档解析**: 解析结果缓存到数据库
- **图片生成**: 差异高亮图片缓存

### 3. 异步处理
- **非阻塞**: 对比完成后立即返回，AI审查后台执行
- **用户体验**: 实时状态反馈，无需等待

## 部署配置

### 1. 环境变量
```bash
# AI服务配置
ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/v3/
ARK_API_KEY=your_api_key
ARK_MODEL=doubao-seed-1-6-flash-250828

# 数据库配置
DATABASE_URL=postgresql://user:password@localhost:5432/contract_diff
```

### 2. 依赖包
```python
# 后端主要依赖
fastapi==0.104.1
uvicorn==0.24.0
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
httpx==0.25.2
PyMuPDF==1.23.8
```

```json
// 前端主要依赖
{
  "react": "^18.2.0",
  "antd": "^5.12.8",
  "axios": "^1.6.2"
}
```

## 监控与日志

### 1. 调试日志
- **后端**: 详细的AI审查流程日志
- **前端**: 轮询状态和错误日志

### 2. 性能监控
- **API响应时间**: AI审查接口性能
- **轮询次数**: 前端轮询效率统计

## 未来优化方向

### 1. 技术优化
- **WebSocket**: 实时推送AI审查结果，替代轮询
- **缓存优化**: Redis缓存热点数据
- **并发处理**: 支持多个对比同时进行AI审查

### 2. 功能扩展
- **多模型支持**: 集成更多AI模型
- **自定义规则**: 用户自定义审查规则
- **历史记录**: AI审查历史查询和统计

### 3. 用户体验
- **进度条**: 显示AI审查进度
- **实时通知**: 审查完成通知
- **批量操作**: 支持批量审查多个对比

## 文档解析与Diff系统技术总结

### 核心技术架构

#### 1. 文档解析流程（5步法）
```
文档上传 → 格式转换 → 文本提取 → 坐标映射 → 差异检测
```

**技术栈**:
- **PDF解析**: PyMuPDF (fitz) - 高性能PDF处理库
- **Word转换**: python-docx + 格式转换
- **坐标计算**: 字符级精确边界框计算
- **差异算法**: Python difflib.SequenceMatcher

#### 2. 字符级坐标系统
- **精度**: 每个字符都有精确的PDF坐标
- **映射**: 字符索引 → PDF坐标 → 图片坐标
- **可视化**: 支持高精度的高亮显示

#### 3. 差异检测算法
- **算法**: 基于LCS（最长公共子序列）的SequenceMatcher
- **类型**: ADD（新增）、DELETE（删除）、MODIFY（修改）
- **智能分类**: 自动判断差异类型和操作

#### 4. 段落级上下文提取
- **定位**: 基于`sub_text_index`精确定位原文位置
- **扩展**: 从字符级差异扩展到段落级上下文
- **边界**: 智能识别句子和段落边界

#### 5. AI审查优化
- **批量处理**: 一次性发送多个差异给AI模型
- **上下文增强**: 提供完整的段落上下文而非仅字符差异
- **重试机制**: 指数退避重试，提高成功率

### 技术优势

1. **高精度**: 字符级差异检测，支持精确的坐标定位
2. **智能化**: AI模型提供专业的法律风险评估
3. **高性能**: 异步处理，不阻塞用户操作
4. **可扩展**: 模块化设计，易于扩展新功能
5. **稳定性**: 完善的错误处理和重试机制

### 关键技术点

1. **PyMuPDF集成**: 利用PyMuPDF的强大PDF处理能力
2. **坐标映射**: 复杂的PDF坐标到图片坐标的转换
3. **差异算法**: 基于SequenceMatcher的智能差异检测
4. **上下文提取**: 从字符位置提取段落级上下文
5. **AI集成**: 与豆包模型的深度集成和优化

### 数据流架构

```
文档上传 → 解析提取 → 坐标映射 → 差异检测 → AI审查 → 结果展示
    ↓         ↓         ↓         ↓         ↓         ↓
  PDF/Word  文本+坐标  字符映射  差异列表  风险评估  前端展示
```

### 性能特点

- **解析速度**: 支持大文档快速解析
- **内存优化**: 流式处理，避免大文档内存溢出
- **并发处理**: 支持多文档同时处理
- **缓存机制**: 智能缓存提升重复访问性能

---

*本文档最后更新时间: 2025-09-24*
